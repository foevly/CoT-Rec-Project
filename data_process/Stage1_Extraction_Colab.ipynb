{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8i4yoeJJi9E"
   },
   "source": [
    "# Stage 1: Personalized Information Extraction\n",
    "\n",
    "This notebook performs Stage 1 of CoT-Rec: extracting user preferences and item perceptions using GPT.\n",
    "\n",
    "## Prerequisites\n",
    "1. Run `preprocess_amazon.py` to generate:\n",
    "   - `datasets/processed/Grocery_and_Gourmet_Food.csv`\n",
    "   - `datasets/processed/Grocery_and_Gourmet_Food.json`\n",
    "2. Train SASRec to generate:\n",
    "   - `SASRec/checkpoint/Grocery_and_Gourmet_Food_rec_list_valid.pkl`\n",
    "   - `SASRec/checkpoint/Grocery_and_Gourmet_Food_rec_list_test.pkl`\n",
    "3. Upload these files to Colab or mount Google Drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGKm4E-iJi9F"
   },
   "source": [
    "## Step 0: Setup and Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5jBg7cWJi9F"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai pandas tqdm -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31976,
     "status": "ok",
     "timestamp": 1763774597543,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "Uy7QyckLJi9F",
    "outputId": "2552c281-21e1-41e2-9899-223272d9ac98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive (if files are stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Or upload files directly in Colab\n",
    "# Set your working directory\n",
    "import os\n",
    "WORK_DIR = '/content/drive/MyDrive/CoT-Rec'  # Change this to your directory\n",
    "os.chdir(WORK_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1763799934652,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "hlr9pb20Ji9F"
   },
   "outputs": [],
   "source": [
    "# Set OpenAI API Key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'yyyapi'  # Replace with your API key\n",
    "\n",
    "# Or use Colab secrets\n",
    "# from google.colab import userdata\n",
    "# os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1HlxlZiJi9F"
   },
   "source": [
    "## Step 1.1: Load Data and Prepare Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1763799982983,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "ERtGL2DJJi9F",
    "outputId": "53b94ced-41e7-4bad-bd41-9762e8dc8b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.1: Loading Data\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "DATASET_NAME = 'Grocery_and_Gourmet_Food'\n",
    "MODE = 'random'\n",
    "K = 10  # Top-k candidates\n",
    "\n",
    "random.seed(2025)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Step 1.1: Loading Data\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2069,
     "status": "ok",
     "timestamp": 1763774690608,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "LcuEzA3xJi9F",
    "outputId": "f8efda98-6981-4a89-af5f-b111890483aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/3] Loading SASRec recommendations...\n",
      "   Loaded 9392 validation entries\n",
      "   Loaded 7661 test entries\n"
     ]
    }
   ],
   "source": [
    "# Load SASRec recommendation lists\n",
    "print(\"\\n[1/3] Loading SASRec recommendations...\")\n",
    "with open(f'SASRec/checkpoint/{DATASET_NAME}_rec_list_valid.pkl', 'rb') as f:\n",
    "    rec_list_valid = pickle.load(f)\n",
    "with open(f'SASRec/checkpoint/{DATASET_NAME}_rec_list_test.pkl', 'rb') as f:\n",
    "    rec_list_test = pickle.load(f)\n",
    "\n",
    "print(f\"   Loaded {len(rec_list_valid)} validation entries\")\n",
    "print(f\"   Loaded {len(rec_list_test)} test entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1763774696550,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "d8kxXM9qJi9G",
    "outputId": "e7551dda-ebb6-4ac9-bb33-c39b3c5eef5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/3] Filtering data...\n",
      "   Filtered to 9392 validation entries\n",
      "   Filtered to 7661 test entries\n"
     ]
    }
   ],
   "source": [
    "# Filter: Only keep cases where target is in top-k\n",
    "print(\"\\n[2/3] Filtering data...\")\n",
    "data_valid = []\n",
    "for u, rec_list, i in rec_list_valid:\n",
    "    if i in rec_list[:K]:\n",
    "        data_valid.append((u, rec_list[:K], i))\n",
    "\n",
    "data_test = []\n",
    "for u, rec_list, i in rec_list_test:\n",
    "    if i in rec_list[:K]:\n",
    "        data_test.append((u, rec_list[:K], i))\n",
    "\n",
    "print(f\"   Filtered to {len(data_valid)} validation entries\")\n",
    "print(f\"   Filtered to {len(data_test)} test entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3701,
     "status": "ok",
     "timestamp": 1763774726054,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "8y5f8MDFJi9G",
    "outputId": "6d00f205-4137-4d48-f515-7a6fcf03ea18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/3] Loading item names and interactions...\n",
      "   Loaded 135194 items\n",
      "   Loaded 4125640 interactions\n",
      "   Number of users: 419876\n",
      "\n",
      "‚úÖ Step 1.1 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Load item names and interaction data\n",
    "print(\"\\n[3/3] Loading item names and interactions...\")\n",
    "with open(f'{DATASET_NAME}.json', 'r') as file:\n",
    "    id2name = json.load(file)\n",
    "    id2name = {int(key): value for key, value in id2name.items()}\n",
    "\n",
    "df = pd.read_csv(f'{DATASET_NAME}.csv', names=['user_id', 'item_id'], usecols=[0, 1])\n",
    "\n",
    "print(f\"   Loaded {len(id2name)} items\")\n",
    "print(f\"   Loaded {len(df)} interactions\")\n",
    "print(f\"   Number of users: {df['user_id'].nunique()}\")\n",
    "print(\"\\n‚úÖ Step 1.1 Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v131bWxNJi9G"
   },
   "source": [
    "## Step 1.2: Build GPT Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1763774726056,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "6S2nnnJSJi9G",
    "outputId": "7d4b67c6-b202-4be9-8115-cca18c5e88ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompt building function ready!\n"
     ]
    }
   ],
   "source": [
    "def build_request(user, rec_list, target, phase, id2name, df, k=10):\n",
    "    \"\"\"\n",
    "    Build GPT prompt for extracting user preferences and item perceptions.\n",
    "\n",
    "    Args:\n",
    "        user: User ID\n",
    "        rec_list: List of candidate item IDs\n",
    "        target: Target item ID\n",
    "        phase: 'valid' or 'test'\n",
    "        id2name: Dictionary mapping item ID to name\n",
    "        df: DataFrame with user-item interactions\n",
    "        k: Number of items in history\n",
    "\n",
    "    Returns:\n",
    "        Prompt string for GPT\n",
    "    \"\"\"\n",
    "    delta = 2 if phase == 'valid' else 1\n",
    "\n",
    "    # Example Interaction History and Candidate Pool\n",
    "    example_history = (\n",
    "        \"Frontier Co-op Ground Chipotle, 1-Pound Bulk\\n\"\n",
    "        \"SunButter No Sugar Added Sunflower Butter\\n\"\n",
    "        \"SweetLeaf Stevia Sweet Drops Lemon Drop\\n\"\n",
    "        \"Frontier Co-op Cinnamon Powder, Ceylon\\n\"\n",
    "        \"SweetLeaf Sweet Drops Stevia Clear\\n\"\n",
    "        \"ALTOIDS Arctic Peppermint Mints\\n\"\n",
    "        \"Organic Cacao Powder, 1lb\\n\"\n",
    "        \"RX Nut Butter, 6 Flavor Variety Pack\\n\"\n",
    "        \"Watkins Pure Almond Extract\\n\"\n",
    "        \"NuNaturals Stevia Syrup\\n\"\n",
    "    )\n",
    "    example_candidates = (\n",
    "        \"A. Shrewd Food Protein Puffs\\n\"\n",
    "        \"B. Carbquik Biscuit & Baking Mix\\n\"\n",
    "        \"C. ChocZero's Strawberry Sugar-Free Syrup\\n\"\n",
    "        \"D. Lakanto Sugar Free Maple Syrup\\n\"\n",
    "        \"E. 4th & Heart Himalayan Pink Salt Grass-Fed Ghee\\n\"\n",
    "        \"F. Amazon Brand - Solimo Medium Roast Coffee Pods\\n\"\n",
    "        \"G. ChocZero's Keto Bark\\n\"\n",
    "        \"H. Swerve Sweetener, Confectioners\\n\"\n",
    "        \"I. Victor Allen's Coffee Caramel Macchiato\\n\"\n",
    "        \"J. Lakanto Golden Monk Fruit Sweetener\\n\"\n",
    "    )\n",
    "\n",
    "    example_output = (\n",
    "        \"{\\n\"\n",
    "        \"  \\\"user_history_perception\\\": {\\n\"\n",
    "        \"    \\\"Frontier Co-op Ground Chipotle, 1-Pound Bulk\\\": \\\"Smoked dried chili powder with a rich smoky and earthy aroma, suitable for Southwest and Mexican cuisine.\\\",\\n\"\n",
    "        \"    \\\"SunButter No Sugar Added Sunflower Butter\\\": \\\"Sugar-free sunflower butter with natural flavor, nutritious and suitable as a healthy snack or spread.\\\",\\n\"\n",
    "        \"    \\\"SweetLeaf Stevia Sweet Drops Lemon Drop\\\": \\\"Liquid stevia drops with zero calories, sugar-free, and a hint of lemon, ideal as a healthy alternative for beverages or baking.\\\",\\n\"\n",
    "        \"    \\\"Frontier Co-op Cinnamon Powder, Ceylon\\\": \\\"Organic Ceylon cinnamon powder with a fresh and sweet aroma, certified natural, commonly used in baking, beverages, and desserts.\\\",\\n\"\n",
    "        \"    \\\"SweetLeaf Sweet Drops Stevia Clear\\\": \\\"Liquid stevia drops with zero calories and sugar-free, suitable for low-carb or sugar-free diets.\\\",\\n\"\n",
    "        \"    \\\"ALTOIDS Arctic Peppermint Mints\\\": \\\"Portable peppermint mints with a cooling flavor, useful as a snack or breath freshener.\\\",\\n\"\n",
    "        \"    \\\"Organic Cacao Powder, 1lb\\\": \\\"Unsweetened cacao powder with a rich dark chocolate flavor, certified natural, ideal for baking and beverages.\\\",\\n\"\n",
    "        \"    \\\"RX Nut Butter, 6 Flavor Variety Pack\\\": \\\"Nut butter in small packages, high protein, low sugar, and available in various flavors, convenient for healthy snacking.\\\",\\n\"\n",
    "        \"    \\\"Watkins Pure Almond Extract\\\": \\\"High-quality almond extract with a rich aroma, suitable for baking or beverage flavoring.\\\",\\n\"\n",
    "        \"    \\\"NuNaturals Stevia Syrup\\\": \\\"Plant-based zero-calorie syrup, sugar-free, suitable as a healthy substitute for desserts and beverages.\\\"\\n\"\n",
    "        \"  },\\n\"\n",
    "        \"  \\\"user_preferences\\\": \\\"The user prefers sugar-free, natural foods, focusing on healthy sweeteners, seasonings, and snacks. They are possibly pursuing weight loss or a low-carb diet, emphasizing portability and variety.\\\",\\n\"\n",
    "        \"  \\\"candidate_temp_perception\\\": {\\n\"\n",
    "        \"    \\\"Shrewd Food Protein Puffs\\\": \\\"High-protein, low-carb, gluten-free healthy snack. [Comment:] As a user, I find this snack very convenient and nutritious, perfectly fitting my dietary habits.\\\",\\n\"\n",
    "        \"    \\\"Carbquik Biscuit & Baking Mix\\\": \\\"Low-carb baking mix suitable for making various low-sugar pastries. [Comment:] I think this product is ideal for creating healthy, low-sugar baked goods and perfectly aligns with my needs.\\\",\\n\"\n",
    "        \"    \\\"ChocZero's Strawberry Sugar-Free Syrup\\\": \\\"Sugar-free strawberry-flavored syrup. [Comment:] This syrup is an excellent addition to my low-sugar diet and is highly practical.\\\",\\n\"\n",
    "        \"    \\\"Lakanto Sugar Free Maple Syrup\\\": \\\"Sugar-free maple syrup, low-carb and natural sweetener. [Comment:] I feel this maple syrup works wonderfully in beverages or baking and aligns well with my healthy eating goals.\\\",\\n\"\n",
    "        \"    \\\"4th & Heart Himalayan Pink Salt Grass-Fed Ghee\\\": \\\"Natural lactose-free grass-fed ghee. [Comment:] This ghee makes me feel connected to natural and healthy cooking, a perfect choice for wholesome meals.\\\",\\n\"\n",
    "        \"    \\\"Amazon Brand - Solimo Medium Roast Coffee Pods\\\": \\\"Medium roast coffee pods convenient for quick coffee preparation. [Comment:] While convenient, this product does not meet my low-sugar dietary focus, so I might not prioritize it.\\\",\\n\"\n",
    "        \"    \\\"ChocZero's Keto Bark\\\": \\\"Sugar-free dark chocolate snack, low-carb with natural ingredients. [Comment:] I love this healthy sugar-free snack; it tastes amazing!\\\",\\n\"\n",
    "        \"    \\\"Swerve Sweetener, Confectioners\\\": \\\"Sugar-free sweetener powder suitable for low-carb and sugar-free baking. [Comment:] As a user, I think this is a perfect sugar substitute and highly practical.\\\",\\n\"\n",
    "        \"    \\\"Victor Allen's Coffee Caramel Macchiato\\\": \\\"Caramel macchiato coffee pods convenient for consumption. [Comment:] This product might not fit my dietary preferences due to its sugar content.\\\",\\n\"\n",
    "        \"    \\\"Lakanto Golden Monk Fruit Sweetener\\\": \\\"Sugar-free monk fruit sweetener, low-carb and zero-calorie. [Comment:] This is one of my favorite healthy sweeteners, ideal for baking or beverages.\\\"\\n\"\n",
    "        \"  },\\n\"\n",
    "        \"  \\\"candidate_perception\\\": {\\n\"\n",
    "        \"    \\\"Shrewd Food Protein Puffs\\\": \\\"Convenient and nutritious snacks\\\",\\n\"\n",
    "        \"    \\\"Carbquik Biscuit & Baking Mix\\\": \\\"Low-carb baking mix\\\",\\n\"\n",
    "        \"    \\\"ChocZero's Strawberry Sugar-Free Syrup\\\": \\\"Low-sugar alternative sweetener\\\",\\n\"\n",
    "        \"    \\\"Lakanto Sugar Free Maple Syrup\\\": \\\"Natural and low-carb sweetener\\\",\\n\"\n",
    "        \"    \\\"4th & Heart Himalayan Pink Salt Grass-Fed Ghee\\\": \\\"Natural and wholesome cooking ingredient\\\",\\n\"\n",
    "        \"    \\\"Amazon Brand - Solimo Medium Roast Coffee Pods\\\": \\\"Convenient but lacks health focus\\\",\\n\"\n",
    "        \"    \\\"ChocZero's Keto Bark\\\": \\\"Healthy sugar-free snack\\\",\\n\"\n",
    "        \"    \\\"Swerve Sweetener, Confectioners\\\": \\\"Excellent sugar substitute\\\",\\n\"\n",
    "        \"    \\\"Victor Allen's Coffee Caramel Macchiato\\\": \\\"Convenient but contains sugar\\\",\\n\"\n",
    "        \"    \\\"Lakanto Golden Monk Fruit Sweetener\\\": \\\"Ideal for low-carb and healthy baking\\\"\\n\"\n",
    "        \"  }\\n\"\n",
    "        \"}\"\n",
    "    )\n",
    "\n",
    "    # Current Interaction History and Candidate Pool\n",
    "    candidates = [id2name[i] for i in rec_list]\n",
    "    candidates = '\\n'.join(candidates)\n",
    "\n",
    "    history = df[df['user_id'] == user]['item_id'].values[-(k + delta):-delta]\n",
    "    history_ = []\n",
    "    for item_id in history:\n",
    "        item_name = id2name[item_id]\n",
    "        history_.append(f\"{item_name}\")\n",
    "    history = '\\n'.join(history_)\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt = (\n",
    "        f\"### Instruction\\n\"\n",
    "        f\"This is a sequential recommendation task involving grocery and gourmet food preferences. Given a user's grocery interaction history and a set of candidate items for the next interaction, your task is as follows:\\n\\n\"\n",
    "        f\"1. Provide an objective description of each item in the user's interaction history, focusing on factual features such as ingredients, health benefits, or notable qualities of each item.\\n\"\n",
    "        f\"2. Based on these descriptions, predict the user's overall preferences and describe their likely personality and tastes in detail in no more than 80 words.\\n\"\n",
    "        f\"   - The summarized user preferences should be based on the frequency and regularity of user behavior rather than occasional occurrences.\\n\"\n",
    "        f\"   - Avoid using generic or vague terms; be specific and relevant.\\n\"\n",
    "        f\"3. Use the predicted preferences to evaluate each candidate item. Each evaluation must include:\\n\"\n",
    "        f\"   - Objective features of the item (factual description).\\n\"\n",
    "        f\"   - User-specific comments based on their preferences, preceded by the tag `[Comment:]` to distinguish them from the factual description.\\n\"\n",
    "        f\"4. Output the result in JSON format with the following fields:\\n\"\n",
    "        f\"   - `user_history_perception`: Objective descriptions for items in the user's interaction history.\\n\"\n",
    "        f\"   - `user_preferences`: A summary of the user's preferences.\\n\"\n",
    "        f\"   - `candidate_temp_perception`: Evaluations for items in the candidate set, including both factual descriptions and user-specific comments (prefixed with `[Comment:]`).\\n\"\n",
    "        f\"   - `candidate_perception`: Summarized user-relevant aspects from `candidate_temp_perception` comments, highlighting the most significant point of interest or concern for each item.\\n\"\n",
    "        f\"5. Ensure the JSON format is strictly correct and complete.\\n\"\n",
    "        f\"   - Every item in the interaction history and candidate set must be included.\\n\"\n",
    "        f\"   - Do not omit any items or use ellipses (...).\\n\"\n",
    "        f\"6. Directly output the JSON format without additional explanations or comments.\\n\"\n",
    "        f\"7. Strictly follow the format and style in the example provided below. Ensure all required fields are present and formatted correctly.\\n\\n\"\n",
    "        f\"### Example\\n\"\n",
    "        f\"**User Item Interaction History:**\\n{example_history}\\n\"\n",
    "        f\"**Candidate Items:**\\n{example_candidates}\\n\\n\"\n",
    "        f\"**Expected Output:**\\n{example_output}\\n\\n\"\n",
    "        f\"### Input\\n\"\n",
    "        f\"**User Item Interaction History:**\\n{history}\\n\"\n",
    "        f\"**Candidate Items:**\\n{candidates}\\n\\n\"\n",
    "        f\"### Output\\n\"\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "print(\"‚úÖ Prompt building function ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxFm_KkMJi9H"
   },
   "source": [
    "## Step 1.3: Create JSONL Files for GPT Batch API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149054,
     "status": "ok",
     "timestamp": 1763776128351,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "wa7SkPYGJi9H",
    "outputId": "506eb876-5103-4d5f-e3b3-3f6073056fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.3: Creating JSONL Files\n",
      "============================================================\n",
      "\n",
      "Processing valid data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 817it [00:06, 101.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part1.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 1607it [00:15, 41.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part2.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 2410it [00:23, 54.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part3.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 3219it [00:30, 89.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part4.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 4025it [00:37, 100.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part5.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 4822it [00:44, 88.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part6.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 5626it [00:50, 99.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part7.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 6416it [00:57, 60.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part8.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 7221it [01:04, 99.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part9.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 8014it [01:11, 62.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part10.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 8823it [01:19, 82.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part11.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid: 9392it [01:24, 111.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part12.jsonl (592 entries)\n",
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 818it [00:07, 80.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part1.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 1615it [00:13, 67.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part2.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 2420it [00:20, 94.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part3.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 3210it [00:27, 80.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part4.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 4024it [00:34, 108.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part5.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 4822it [00:40, 105.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part6.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 5613it [00:47, 98.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part7.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 6414it [00:53, 98.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part8.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 7216it [01:01, 94.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part9.jsonl (800 entries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 7661it [01:04, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part10.jsonl (461 entries)\n",
      "\n",
      "‚úÖ Step 1.3 Complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('gpt_sft_data', exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Step 1.3: Creating JSONL Files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "MAX_ENTRIES_PER_FILE = 800  # OpenAI Batch API limit\n",
    "\n",
    "for phase in ['valid', 'test']:\n",
    "    print(f\"\\nProcessing {phase} data...\")\n",
    "    data = data_valid if phase == 'valid' else data_test\n",
    "    file_index = 1\n",
    "    entries = []\n",
    "\n",
    "    for idx, (user, rec_list, target) in tqdm(enumerate(data), desc=f\"Processing {phase}\"):\n",
    "        random.shuffle(rec_list)  # Shuffle for robustness\n",
    "\n",
    "        if MODE == 'random':\n",
    "            prompt = build_request(user, rec_list, target, phase, id2name, df, K)\n",
    "\n",
    "            data_entry = {\n",
    "                \"custom_id\": str(user),\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "            entries.append(data_entry)\n",
    "\n",
    "            # Save when reaching max entries\n",
    "            if len(entries) == MAX_ENTRIES_PER_FILE:\n",
    "                output_file = f'gpt_sft_data/{DATASET_NAME}_{MODE}_{phase}_part{file_index}.jsonl'\n",
    "                with open(output_file, 'w', encoding='utf-8') as file:\n",
    "                    for entry in entries:\n",
    "                        file.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "                print(f\"   Saved {output_file} ({len(entries)} entries)\")\n",
    "                entries = []\n",
    "                file_index += 1\n",
    "\n",
    "    # Save remaining entries\n",
    "    if entries:\n",
    "        output_file = f'gpt_sft_data/{DATASET_NAME}_{MODE}_{phase}_part{file_index}.jsonl'\n",
    "        with open(output_file, 'w', encoding='utf-8') as file:\n",
    "            for entry in entries:\n",
    "                file.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "        print(f\"   Saved {output_file} ({len(entries)} entries)\")\n",
    "\n",
    "print(\"\\n‚úÖ Step 1.3 Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hpZWR17Ji9H"
   },
   "source": [
    "## Step 1.4-1.6: Upload to OpenAI Batch API and Submit Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1763799940284,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "0Ej10cTAJi9H",
    "outputId": "3ff53481-7190-4586-dbff-af703899299c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.4-1.6: OpenAI Batch API Processing\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import time\n",
    "import glob\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Step 1.4-1.6: OpenAI Batch API Processing\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19486471,
     "status": "ok",
     "timestamp": 1763795670873,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "A36yIhs7LN3H",
    "outputId": "b4e738ae-5b1a-49a8-84a4-08bb41a2aa9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing VALID phase\n",
      "============================================================\n",
      "Found 12 file(s) to process\n",
      "\n",
      "[1/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part1.jsonl...\n",
      "  Estimated tokens: ~1,932,369\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-W1UJYoHFi9DPiDy9vdWx8W\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692116c4964c8190a208ed97ee5d9f38\n",
      "    Status: validating\n",
      "\n",
      "[2/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part10.jsonl...\n",
      "  Estimated tokens: ~1,933,694\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-6RRMp97o74dP6pw5m6NwHt\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69211c9ed1d481908dcfca710b96f265\n",
      "    Status: validating\n",
      "\n",
      "[3/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part11.jsonl...\n",
      "  Estimated tokens: ~1,937,670\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-UBkpL9fG55KQpBnDXpvnNJ\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_6921210e6628819084a855be873c52c4\n",
      "    Status: validating\n",
      "\n",
      "[4/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part12.jsonl...\n",
      "  Estimated tokens: ~1,434,154\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-LC4pww9GzNCgufGh4NQZmS\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_6921279f141c8190a54380a7e5a05826\n",
      "    Status: validating\n",
      "\n",
      "[5/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part2.jsonl...\n",
      "  Estimated tokens: ~1,931,885\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-XuNy347ZkMdLWk8SKb37nJ\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692133cb90488190a90ab9c291edbd76\n",
      "    Status: validating\n",
      "\n",
      "[6/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part3.jsonl...\n",
      "  Estimated tokens: ~1,936,382\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-Pdeijkr6HAjUQ7irmaPCdC\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692136efb60c819080a48038f5569d35\n",
      "    Status: validating\n",
      "\n",
      "[7/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part4.jsonl...\n",
      "  Estimated tokens: ~1,932,124\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-AQRU2qs9tdpX3HcwXY8gvK\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69213f12ce008190830d43287ab88e86\n",
      "    Status: validating\n",
      "\n",
      "[8/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part5.jsonl...\n",
      "  Estimated tokens: ~1,936,159\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-F5YaW3LSnt4TMd2kiJ9Lhz\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692140abcbe88190a7fc15b1fa609fab\n",
      "    Status: validating\n",
      "\n",
      "[9/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part6.jsonl...\n",
      "  Estimated tokens: ~1,936,788\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-VJMJ71sLYV4mEB2yTYwNH5\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_6921429ff4048190bdca6945cdbcd13b\n",
      "    Status: validating\n",
      "\n",
      "[10/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part7.jsonl...\n",
      "  Estimated tokens: ~1,932,753\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-MD2TjGAp2xUopC6vD1pgzy\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692146b7afd881909f3fa3c5a1c851e8\n",
      "    Status: validating\n",
      "\n",
      "[11/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part8.jsonl...\n",
      "  Estimated tokens: ~1,925,634\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-GeZ5ftmRgPQgHeP2h2YwG5\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69214ad0fc748190b3955d6ce8fac6b0\n",
      "    Status: validating\n",
      "\n",
      "[12/12] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_valid_part9.jsonl...\n",
      "  Estimated tokens: ~1,933,708\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-DWZPJXCMz5pvJeQ3wy9axY\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69214fbf80d8819092a13695afe0b079\n",
      "    Status: validating\n",
      "\n",
      "============================================================\n",
      "Processing TEST phase\n",
      "============================================================\n",
      "Found 10 file(s) to process\n",
      "\n",
      "[1/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part1.jsonl...\n",
      "  Estimated tokens: ~1,950,454\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-6bBHUjN8UE9btcTpoRj8v4\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69214fcb304c8190b6942b14d96ffbac\n",
      "    Status: validating\n",
      "\n",
      "[2/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part10.jsonl...\n",
      "  Estimated tokens: ~1,125,970\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 2 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-6pEwExJGFxRgBWUdPuLG5r\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692153c16fa08190bb76713f107a4adc\n",
      "    Status: validating\n",
      "\n",
      "[3/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part2.jsonl...\n",
      "  Estimated tokens: ~1,946,200\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-Gp1qLrUyThD7e6vqXQis24\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692154a4425c81908283d98a48cc9f75\n",
      "    Status: validating\n",
      "\n",
      "[4/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part3.jsonl...\n",
      "  Estimated tokens: ~1,948,962\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-BVMKiCpQjPEPZBfSfqS8tg\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692158df71b081908d2e7552fbddab38\n",
      "    Status: validating\n",
      "\n",
      "[5/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part4.jsonl...\n",
      "  Estimated tokens: ~1,947,964\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-LFFh9cH3rZiM2H3cUej7uM\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692159c2d3388190a3142bff116c6601\n",
      "    Status: validating\n",
      "\n",
      "[6/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part5.jsonl...\n",
      "  Estimated tokens: ~1,946,899\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-NzG8mofJVwN755QjA6dDkn\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69215aa4a9b48190b3b81110200777a3\n",
      "    Status: validating\n",
      "\n",
      "[7/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part6.jsonl...\n",
      "  Estimated tokens: ~1,951,853\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-JuZZhVWL14xC19hz9Qcz94\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69215b67b9c08190b952db9d5690e813\n",
      "    Status: validating\n",
      "\n",
      "[8/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part7.jsonl...\n",
      "  Estimated tokens: ~1,953,309\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-1zcCe4u4s85mzJuFQG8ozG\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69215d0094788190ba8b2cabc50ef0b5\n",
      "    Status: validating\n",
      "\n",
      "[9/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part8.jsonl...\n",
      "  Estimated tokens: ~1,953,267\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-McAh5dKTTymZxbo7nAZV9r\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_69215dc707e0819094310a535bbec30f\n",
      "    Status: validating\n",
      "\n",
      "[10/10] Processing gpt_sft_data/Grocery_and_Gourmet_Food_random_test_part9.jsonl...\n",
      "  Estimated tokens: ~1,950,920\n",
      "\n",
      "  ‚è≥ Checking batch queue status...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚è≥ 1 batch(es) still processing...\n",
      "  ‚úÖ No batches in queue, proceeding...\n",
      "  üì§ Uploading file...\n",
      "    ‚úÖ File ID: file-NatSWveZUTJHKUJsgoqvwm\n",
      "  üì§ Submitting batch job...\n",
      "    ‚úÖ Batch ID: batch_692162d671b88190b8f12b80378ba86b\n",
      "    Status: validating\n",
      "\n",
      "============================================================\n",
      "‚úÖ Batch submission complete!\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è  Note: Batch processing can take hours.\n",
      "   Use Step 1.6 to check status periodically.\n",
      "\n",
      "üìä Submitted batches:\n",
      "  VALID: 12 batch(es)\n",
      "  TEST: 10 batch(es)\n"
     ]
    }
   ],
   "source": [
    "# Process each JSONL file SEQUENTIALLY to avoid token limit\n",
    "# OpenAI has a limit of 2M enqueued tokens per model per organization\n",
    "batch_info = {}  # Store batch IDs for later retrieval\n",
    "\n",
    "import time\n",
    "\n",
    "def estimate_tokens_from_file(jsonl_file):\n",
    "    \"\"\"Rough estimate of tokens in a JSONL file\"\"\"\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        total_chars = sum(len(line) for line in f)\n",
    "    # Rough estimate: 1 token ‚âà 4 characters\n",
    "    return int(total_chars / 4)\n",
    "\n",
    "def wait_for_batch_space(client, model='gpt-4o-mini', max_wait_minutes=60):\n",
    "    \"\"\"Wait until there's space in the batch queue\"\"\"\n",
    "    print(f\"\\n  ‚è≥ Checking batch queue status...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        # List all batches\n",
    "        batches = client.batches.list(limit=100)\n",
    "\n",
    "        # Count enqueued tokens (rough estimate)\n",
    "        in_progress_batches = [b for b in batches.data if b.status in ['validating', 'in_progress', 'finalizing']]\n",
    "\n",
    "        if len(in_progress_batches) == 0:\n",
    "            print(f\"  ‚úÖ No batches in queue, proceeding...\")\n",
    "            return True\n",
    "\n",
    "        print(f\"  ‚è≥ {len(in_progress_batches)} batch(es) still processing...\")\n",
    "\n",
    "        # Check if we've waited too long\n",
    "        elapsed_minutes = (time.time() - start_time) / 60\n",
    "        if elapsed_minutes > max_wait_minutes:\n",
    "            print(f\"  ‚ö†Ô∏è  Waited {elapsed_minutes:.1f} minutes. Proceeding anyway...\")\n",
    "            return True\n",
    "\n",
    "        # Wait before checking again\n",
    "        time.sleep(30)  # Check every 30 seconds\n",
    "\n",
    "for phase in ['valid', 'test']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {phase.upper()} phase\")\n",
    "    print(f\"{'='*60}\")\n",
    "    batch_info[phase] = {}\n",
    "\n",
    "    # Find all part files for this phase\n",
    "    jsonl_files = sorted(glob.glob(f'gpt_sft_data/{DATASET_NAME}_{MODE}_{phase}_part*.jsonl'))\n",
    "\n",
    "    print(f\"Found {len(jsonl_files)} file(s) to process\")\n",
    "\n",
    "    for idx, jsonl_file in enumerate(jsonl_files, 1):\n",
    "        part_num = jsonl_file.split('_part')[1].split('.')[0]\n",
    "        print(f\"\\n[{idx}/{len(jsonl_files)}] Processing {jsonl_file}...\")\n",
    "\n",
    "        # Estimate tokens\n",
    "        estimated_tokens = estimate_tokens_from_file(jsonl_file)\n",
    "        print(f\"  Estimated tokens: ~{estimated_tokens:,}\")\n",
    "\n",
    "        # Wait for queue space if not first file\n",
    "        if idx > 1:\n",
    "            wait_for_batch_space(client)\n",
    "\n",
    "        try:\n",
    "            # Step 1.4: Upload file\n",
    "            print(f\"  üì§ Uploading file...\")\n",
    "            file_object = client.files.create(\n",
    "                file=Path(jsonl_file),\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "            file_id = file_object.id\n",
    "            print(f\"    ‚úÖ File ID: {file_id}\")\n",
    "\n",
    "            # Step 1.5: Submit batch job\n",
    "            print(f\"  üì§ Submitting batch job...\")\n",
    "            batch = client.batches.create(\n",
    "                input_file_id=file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\"\n",
    "            )\n",
    "            batch_id = batch.id\n",
    "            print(f\"    ‚úÖ Batch ID: {batch_id}\")\n",
    "            print(f\"    Status: {batch.status}\")\n",
    "\n",
    "            batch_info[phase][part_num] = {\n",
    "                'file_id': file_id,\n",
    "                'batch_id': batch_id,\n",
    "                'jsonl_file': jsonl_file\n",
    "            }\n",
    "\n",
    "            # If batch failed immediately, check why\n",
    "            if batch.status == 'failed':\n",
    "                if hasattr(batch, 'errors') and batch.errors:\n",
    "                    error_msg = batch.errors.data[0].message if batch.errors.data else \"Unknown error\"\n",
    "                    print(f\"    ‚ùå Batch failed: {error_msg}\")\n",
    "                    if 'token_limit_exceeded' in error_msg:\n",
    "                        print(f\"    ‚è≥ Waiting 2 minutes before retrying...\")\n",
    "                        time.sleep(120)\n",
    "                        # Retry once\n",
    "                        batch = client.batches.create(\n",
    "                            input_file_id=file_id,\n",
    "                            endpoint=\"/v1/chat/completions\",\n",
    "                            completion_window=\"24h\"\n",
    "                        )\n",
    "                        batch_id = batch.id\n",
    "                        batch_info[phase][part_num]['batch_id'] = batch_id\n",
    "                        print(f\"    ‚úÖ Retry Batch ID: {batch_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Error: {e}\")\n",
    "            if 'token_limit_exceeded' in str(e):\n",
    "                print(f\"    ‚è≥ Token limit reached. Waiting 2 minutes...\")\n",
    "                time.sleep(120)\n",
    "                # Retry\n",
    "                try:\n",
    "                    batch = client.batches.create(\n",
    "                        input_file_id=file_id,\n",
    "                        endpoint=\"/v1/chat/completions\",\n",
    "                        completion_window=\"24h\"\n",
    "                    )\n",
    "                    batch_id = batch.id\n",
    "                    batch_info[phase][part_num] = {\n",
    "                        'file_id': file_id,\n",
    "                        'batch_id': batch_id,\n",
    "                        'jsonl_file': jsonl_file\n",
    "                    }\n",
    "                    print(f\"    ‚úÖ Retry successful. Batch ID: {batch_id}\")\n",
    "                except Exception as retry_e:\n",
    "                    print(f\"    ‚ùå Retry also failed: {retry_e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Batch submission complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è  Note: Batch processing can take hours.\")\n",
    "print(\"   Use Step 1.6 to check status periodically.\")\n",
    "print(f\"\\nüìä Submitted batches:\")\n",
    "for phase in ['valid', 'test']:\n",
    "    if phase in batch_info:\n",
    "        print(f\"  {phase.upper()}: {len(batch_info[phase])} batch(es)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4829,
     "status": "ok",
     "timestamp": 1763796812547,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "n18W9a0HJi9H",
    "outputId": "fffcad94-1cee-42a9-b554-34ca1077925d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking batch status...\n",
      "\n",
      "VALID phase:\n",
      "  Part 1: Status = completed\n",
      "    Output file ID: file-S5t7VVgFTXxRr74QMzWppC\n",
      "    Error file ID: None\n",
      "  Part 10: Status = completed\n",
      "    Output file ID: file-5bxmZssU8C3BBMjAV6JeQg\n",
      "    Error file ID: None\n",
      "  Part 11: Status = completed\n",
      "    Output file ID: file-ECC3nHwvYuymdjhf7r86tQ\n",
      "    Error file ID: None\n",
      "  Part 12: Status = completed\n",
      "    Output file ID: file-QdHuA27NSBjUXPRccGSkBx\n",
      "    Error file ID: None\n",
      "  Part 2: Status = completed\n",
      "    Output file ID: file-DW13stgC7YCS1rk21Sp3Kt\n",
      "    Error file ID: None\n",
      "  Part 3: Status = completed\n",
      "    Output file ID: file-DT2kBWRSAkGeE5dCC4t1VC\n",
      "    Error file ID: None\n",
      "  Part 4: Status = completed\n",
      "    Output file ID: file-2YMc2eh9yS5A2196aFprf6\n",
      "    Error file ID: None\n",
      "  Part 5: Status = completed\n",
      "    Output file ID: file-W9xW9Ftt5ST55STMhxjNWU\n",
      "    Error file ID: None\n",
      "  Part 6: Status = completed\n",
      "    Output file ID: file-8Uee39X9J9ZbrywAVr5Bu1\n",
      "    Error file ID: None\n",
      "  Part 7: Status = completed\n",
      "    Output file ID: file-3vD93UFPTPBvWWhaiByV1a\n",
      "    Error file ID: None\n",
      "  Part 8: Status = completed\n",
      "    Output file ID: file-Pv7k7i3SHm4FG3MJp7oGyn\n",
      "    Error file ID: None\n",
      "  Part 9: Status = completed\n",
      "    Output file ID: file-KujRBWPqYVcJgV47mKec1C\n",
      "    Error file ID: None\n",
      "\n",
      "TEST phase:\n",
      "  Part 1: Status = failed\n",
      "    ‚ùå Batch failed!\n",
      "  Part 10: Status = completed\n",
      "    Output file ID: file-SWDnJn5vJjXYdwxVm2BJHk\n",
      "    Error file ID: None\n",
      "  Part 2: Status = completed\n",
      "    Output file ID: file-QoNd9hbu4fignffCAW7Rsh\n",
      "    Error file ID: None\n",
      "  Part 3: Status = completed\n",
      "    Output file ID: file-J1G4aFYGbKDthEnMUyTn6e\n",
      "    Error file ID: None\n",
      "  Part 4: Status = completed\n",
      "    Output file ID: file-G4rMuf8gD5HKMtiGqtmS6f\n",
      "    Error file ID: None\n",
      "  Part 5: Status = completed\n",
      "    Output file ID: file-U7dTGUVNPyt9EtoyuVQv9B\n",
      "    Error file ID: None\n",
      "  Part 6: Status = completed\n",
      "    Output file ID: file-4eMDt3vhftY8Fo4trA61fX\n",
      "    Error file ID: None\n",
      "  Part 7: Status = completed\n",
      "    Output file ID: file-NwAHM2M5kkf3dfxFuFHEq2\n",
      "    Error file ID: None\n",
      "  Part 8: Status = completed\n",
      "    Output file ID: file-4jcS1WSv4ZZRLhMh63Tjhk\n",
      "    Error file ID: None\n",
      "  Part 9: Status = completed\n",
      "    Output file ID: file-R4ooeBbCRWGHJLbtMhv1NT\n",
      "    Error file ID: None\n"
     ]
    }
   ],
   "source": [
    "# Step 1.6: Check batch status\n",
    "print(\"Checking batch status...\")\n",
    "for phase in ['valid', 'test']:\n",
    "    print(f\"\\n{phase.upper()} phase:\")\n",
    "    for part_num, info in batch_info[phase].items():\n",
    "        batch = client.batches.retrieve(info['batch_id'])\n",
    "        print(f\"  Part {part_num}: Status = {batch.status}\")\n",
    "        if batch.status == 'completed':\n",
    "            print(f\"    Output file ID: {batch.output_file_id}\")\n",
    "            print(f\"    Error file ID: {batch.error_file_id}\")\n",
    "            info['output_file_id'] = batch.output_file_id\n",
    "            info['error_file_id'] = batch.error_file_id\n",
    "        elif batch.status == 'failed':\n",
    "            print(f\"    ‚ùå Batch failed!\")\n",
    "            if batch.error_file_id:\n",
    "                print(f\"    Error file ID: {batch.error_file_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa8RreTLJi9H"
   },
   "source": [
    "## Step 1.7: Download GPT Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40873,
     "status": "ok",
     "timestamp": 1763796891348,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "iPoqKV_XJi9H",
    "outputId": "7232798a-d045-4a7e-9fa3-6cca32803432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.7: Downloading Results\n",
      "============================================================\n",
      "\n",
      "Downloading valid results...\n",
      "  Downloading part 1...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part1_result.jsonl\n",
      "  Downloading part 10...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part10_result.jsonl\n",
      "  Downloading part 11...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part11_result.jsonl\n",
      "  Downloading part 12...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part12_result.jsonl\n",
      "  Downloading part 2...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part2_result.jsonl\n",
      "  Downloading part 3...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part3_result.jsonl\n",
      "  Downloading part 4...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part4_result.jsonl\n",
      "  Downloading part 5...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part5_result.jsonl\n",
      "  Downloading part 6...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part6_result.jsonl\n",
      "  Downloading part 7...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part7_result.jsonl\n",
      "  Downloading part 8...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part8_result.jsonl\n",
      "  Downloading part 9...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_valid_part9_result.jsonl\n",
      "\n",
      "Downloading test results...\n",
      "  ‚ö†Ô∏è  Part 1 not completed yet\n",
      "  Downloading part 10...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part10_result.jsonl\n",
      "  Downloading part 2...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part2_result.jsonl\n",
      "  Downloading part 3...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part3_result.jsonl\n",
      "  Downloading part 4...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part4_result.jsonl\n",
      "  Downloading part 5...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part5_result.jsonl\n",
      "  Downloading part 6...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part6_result.jsonl\n",
      "  Downloading part 7...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part7_result.jsonl\n",
      "  Downloading part 8...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part8_result.jsonl\n",
      "  Downloading part 9...\n",
      "    Saved: Grocery_and_Gourmet_Food_random_test_part9_result.jsonl\n",
      "\n",
      "‚úÖ Step 1.7 Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Step 1.7: Downloading Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for phase in ['valid', 'test']:\n",
    "    print(f\"\\nDownloading {phase} results...\")\n",
    "    for part_num, info in batch_info[phase].items():\n",
    "        if 'output_file_id' in info:\n",
    "            print(f\"  Downloading part {part_num}...\")\n",
    "            content = client.files.content(file_id=info['output_file_id'])\n",
    "            output_file = f\"{DATASET_NAME}_{MODE}_{phase}_part{part_num}_result.jsonl\"\n",
    "            content.write_to_file(output_file)\n",
    "            print(f\"    Saved: {output_file}\")\n",
    "            info['result_file'] = output_file\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Part {part_num} not completed yet\")\n",
    "\n",
    "print(\"\\n‚úÖ Step 1.7 Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK1Ypw7qJi9H"
   },
   "source": [
    "## Step 1.8: Parse and Extract Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13434,
     "status": "ok",
     "timestamp": 1763799150009,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "y7lha59Inuwn",
    "outputId": "23e3c144-1720-4238-8681-c191b3596831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive (if files are stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Or upload files directly in Colab\n",
    "# Set your working directory\n",
    "import os\n",
    "WORK_DIR = '/content/drive/MyDrive/CoT-Rec'  # Change this to your directory\n",
    "os.chdir(WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1763799957484,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "MbPxn7s-n-dJ",
    "outputId": "4777438d-443f-40b8-9c94-5c7599dba453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parsing functions ready!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_json_content(content):\n",
    "    \"\"\"Clean JSON-like content by removing trailing commas.\"\"\"\n",
    "    cleaned_content = re.sub(r',\\s*$', '', content.strip())\n",
    "    return cleaned_content\n",
    "\n",
    "def parse_dict_content(content, custom_id, field_name):\n",
    "    \"\"\"Parse and clean dictionary-like content.\"\"\"\n",
    "    cleaned_content = clean_json_content(content)\n",
    "    try:\n",
    "        return json.loads(\"{\" + cleaned_content + \"}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing {field_name} (custom_id: {custom_id}): {content[:100]}...\")\n",
    "        return {}\n",
    "\n",
    "def is_valid_extraction(content_dict):\n",
    "    \"\"\"Validate if all required fields are present.\"\"\"\n",
    "    required_fields = [\"user_preferences\", \"candidate_perception\"]\n",
    "    return all(field in content_dict and content_dict[field] for field in required_fields)\n",
    "\n",
    "def process_jsonl_file(file_path):\n",
    "    \"\"\"\n",
    "    Process JSONL result file and extract user preferences and candidate perceptions.\n",
    "\n",
    "    Returns:\n",
    "        custom_id_to_content: Dictionary mapping user_id to extracted content\n",
    "        failed_custom_ids: List of failed user IDs\n",
    "    \"\"\"\n",
    "    custom_id_to_content = {}\n",
    "    failed_custom_ids = []\n",
    "\n",
    "    # Regex patterns to extract required fields\n",
    "    patterns = {\n",
    "        \"user_history_perception\": r'\"user_history_perception\"\\s*:\\s*\\{(.*?)\\}',\n",
    "        \"user_preferences\": r'\"user_preferences\"\\s*:\\s*\"(.*?)\"',\n",
    "        \"candidate_temp_perception\": r'\"candidate_temp_perception\"\\s*:\\s*\\{(.*?)\\}',\n",
    "        \"candidate_perception\": r'\"candidate_perception\"\\s*:\\s*\\{(.*?)\\}'\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                custom_id = data.get('custom_id')\n",
    "                content = data.get('response', {}).get('body', {}).get('choices', [])[0].get('message', {}).get('content')\n",
    "\n",
    "                if not custom_id:\n",
    "                    print(f\"Line {line_number}: Missing custom_id.\")\n",
    "                    failed_custom_ids.append(None)\n",
    "                    continue\n",
    "\n",
    "                if not content:\n",
    "                    print(f\"Line {line_number}: Missing content for custom_id {custom_id}.\")\n",
    "                    failed_custom_ids.append(custom_id)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Try parsing content as JSON directly\n",
    "                    content_json = json.loads(content)\n",
    "                    if is_valid_extraction(content_json):\n",
    "                        custom_id_to_content[custom_id] = {\n",
    "                            \"user_history_perception\": content_json.get(\"user_history_perception\", {}),\n",
    "                            \"user_preferences\": content_json.get(\"user_preferences\", \"\"),\n",
    "                            \"candidate_temp_perception\": content_json.get(\"candidate_temp_perception\", {}),\n",
    "                            \"candidate_perception\": content_json.get(\"candidate_perception\", {})\n",
    "                        }\n",
    "                    else:\n",
    "                        print(f\"Missing fields for custom_id {custom_id}.\")\n",
    "                        failed_custom_ids.append(custom_id)\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    # Fall back to regex extraction\n",
    "                    extracted_content = {}\n",
    "                    for field, pattern in patterns.items():\n",
    "                        match = re.search(pattern, content, re.DOTALL)\n",
    "                        if match:\n",
    "                            if field == \"user_preferences\":\n",
    "                                extracted_content[field] = match.group(1)\n",
    "                            else:\n",
    "                                extracted_content[field] = parse_dict_content(match.group(1), custom_id, field)\n",
    "                        # else:\n",
    "                        #     print(f\"Missing {field} for custom_id {custom_id}.\")\n",
    "                        #     failed_custom_ids.append(custom_id)\n",
    "                        # Note: Only user_preferences and candidate_perception are required\n",
    "                        # Other fields (user_history_perception, candidate_temp_perception) are optional\n",
    "                        # and won't cause failure if missing\n",
    "\n",
    "                    if is_valid_extraction(extracted_content):\n",
    "                        custom_id_to_content[custom_id] = {\n",
    "                            \"user_history_perception\": extracted_content.get(\"user_history_perception\", {}),\n",
    "                            \"user_preferences\": extracted_content.get(\"user_preferences\", \"\"),\n",
    "                            \"candidate_temp_perception\": extracted_content.get(\"candidate_temp_perception\", {}),\n",
    "                            \"candidate_perception\": extracted_content.get(\"candidate_perception\", {})\n",
    "                        }\n",
    "                    else:\n",
    "                        failed_custom_ids.append(custom_id)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Line {line_number}: Error decoding JSON: {e}\")\n",
    "                failed_custom_ids.append(custom_id if 'custom_id' in locals() else None)\n",
    "\n",
    "    unique_failed_custom_ids = list(set(failed_custom_ids))\n",
    "    return custom_id_to_content, unique_failed_custom_ids\n",
    "\n",
    "print(\"‚úÖ Parsing functions ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Wd2alBToCcD"
   },
   "source": [
    "only extracts 2: user_preferences and candidate_perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1763797064153,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "rE_swIspJi9H",
    "outputId": "3b13536a-396a-4f0d-c829-0b220cce67a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parsing functions ready!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_json_content(content):\n",
    "    \"\"\"Clean JSON-like content by removing trailing commas.\"\"\"\n",
    "    cleaned_content = re.sub(r',\\s*$', '', content.strip())\n",
    "    return cleaned_content\n",
    "\n",
    "def parse_dict_content(content, custom_id, field_name):\n",
    "    \"\"\"Parse and clean dictionary-like content.\"\"\"\n",
    "    cleaned_content = clean_json_content(content)\n",
    "    try:\n",
    "        return json.loads(\"{\" + cleaned_content + \"}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing {field_name} (custom_id: {custom_id}): {content[:100]}...\")\n",
    "        return {}\n",
    "\n",
    "def is_valid_extraction(content_dict):\n",
    "    \"\"\"Validate if all required fields are present.\"\"\"\n",
    "    required_fields = [\"user_preferences\", \"candidate_perception\"]\n",
    "    return all(field in content_dict and content_dict[field] for field in required_fields)\n",
    "\n",
    "def process_jsonl_file(file_path):\n",
    "    \"\"\"\n",
    "    Process JSONL result file and extract user preferences and candidate perceptions.\n",
    "\n",
    "    Returns:\n",
    "        custom_id_to_content: Dictionary mapping user_id to extracted content\n",
    "        failed_custom_ids: List of failed user IDs\n",
    "    \"\"\"\n",
    "    custom_id_to_content = {}\n",
    "    failed_custom_ids = []\n",
    "\n",
    "    # Regex patterns to extract required fields\n",
    "    patterns = {\n",
    "        \"user_preferences\": r'\"user_preferences\"\\s*:\\s*\"(.*?)\"',\n",
    "        \"candidate_perception\": r'\"candidate_perception\"\\s*:\\s*\\{(.*?)\\}'\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                custom_id = data.get('custom_id')\n",
    "                content = data.get('response', {}).get('body', {}).get('choices', [])[0].get('message', {}).get('content')\n",
    "\n",
    "                if not custom_id:\n",
    "                    print(f\"Line {line_number}: Missing custom_id.\")\n",
    "                    failed_custom_ids.append(None)\n",
    "                    continue\n",
    "\n",
    "                if not content:\n",
    "                    print(f\"Line {line_number}: Missing content for custom_id {custom_id}.\")\n",
    "                    failed_custom_ids.append(custom_id)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Try parsing content as JSON directly\n",
    "                    content_json = json.loads(content)\n",
    "                    if is_valid_extraction(content_json):\n",
    "                        custom_id_to_content[custom_id] = {\n",
    "                            \"user_preferences\": content_json.get(\"user_preferences\", \"\"),\n",
    "                            \"candidate_perception\": content_json.get(\"candidate_perception\", {})\n",
    "                        }\n",
    "                    else:\n",
    "                        print(f\"Missing fields for custom_id {custom_id}.\")\n",
    "                        failed_custom_ids.append(custom_id)\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    # Fall back to regex extraction\n",
    "                    extracted_content = {}\n",
    "                    for field, pattern in patterns.items():\n",
    "                        match = re.search(pattern, content, re.DOTALL)\n",
    "                        if match:\n",
    "                            if field == \"user_preferences\":\n",
    "                                extracted_content[field] = match.group(1)\n",
    "                            else:\n",
    "                                extracted_content[field] = parse_dict_content(match.group(1), custom_id, field)\n",
    "                        else:\n",
    "                            print(f\"Missing {field} for custom_id {custom_id}.\")\n",
    "                            failed_custom_ids.append(custom_id)\n",
    "\n",
    "                    if is_valid_extraction(extracted_content):\n",
    "                        custom_id_to_content[custom_id] = extracted_content\n",
    "                    else:\n",
    "                        failed_custom_ids.append(custom_id)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Line {line_number}: Error decoding JSON: {e}\")\n",
    "                failed_custom_ids.append(custom_id if 'custom_id' in locals() else None)\n",
    "\n",
    "    unique_failed_custom_ids = list(set(failed_custom_ids))\n",
    "    return custom_id_to_content, unique_failed_custom_ids\n",
    "\n",
    "print(\"‚úÖ Parsing functions ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11843,
     "status": "ok",
     "timestamp": 1763800002918,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "w-kbV-EYJi9I",
    "outputId": "a2157c96-dcfe-4f00-a253-d41dda32f8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.8: Parsing GPT Results\n",
      "============================================================\n",
      "\n",
      "Processing valid phase...\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part10_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 326514): \n",
      "    \"Kiss My Keto Bread Zero Carb (0g-Net) ‚Äì Wheat Bread Loaf, Low Calorie Bread ‚Äì Sugar Free Bread...\n",
      "Error parsing candidate_temp_perception (custom_id: 326680): \n",
      "    \"FONDX Fondant, Vanilla Flavor, Blue, 5 lb\": \"Vanilla-flavored blue fondant, ideal for covering...\n",
      "Error parsing candidate_temp_perception (custom_id: 335925): \n",
      "    \"NUTPODS Toasted Marshmallow Unsweetened Dairy Free Creamer, 11.2 FZ\": \"Unsweetened, dairy-free...\n",
      "Error parsing candidate_temp_perception (custom_id: 341773): \n",
      "    \"Hint Water Peach, Pure Water Infused with Peach, Zero Sugar, Zero Calories, Zero Sweeteners, Z...\n",
      "Error parsing candidate_temp_perception (custom_id: 345622): \n",
      "    \"Sparkling Ice +Caffeine Tropical Punch Sparkling Water with Caffeine, Zero Sugar, with Antioxi...\n",
      "Error parsing candidate_temp_perception (custom_id: 347218): \n",
      "    \"LifeSavers Orange Mints Candy Bag, 13 oz\": \"Minty hard candy with an orange flavor, known for ...\n",
      "Error parsing candidate_perception (custom_id: 348345): \n",
      "    \"Turmeric Gingerade, Ginger Soother by The Ginger People ‚Äì Drug Free Digestive Health, Turmeric...\n",
      "    Extracted 799 entries\n",
      "    Failed: 1 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part11_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 375726): \n",
      "    \"CHOMPS Grass Fed Sea Salt Beef Jerky Snack Sticks, Keto, Whole30, Paleo, Gluten Free, Sugar Fr...\n",
      "    Extracted 800 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part12_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 401055): \n",
      "    \"Slim Jim Original 'N Cheese, Original Flavor, 0.9 oz 10 ct\": \"Meat stick snacks with cheese fl...\n",
      "Error parsing candidate_temp_perception (custom_id: 408656): \n",
      "    \"Wheat Thins Crackers, Sundried Tomato & Basil Flavor, 1 Family Size Box (15 oz.)\": \"Flavorful ...\n",
      "Error parsing candidate_temp_perception (custom_id: 409272): \n",
      "    \"Maruchan Ramen Creamy Chicken Flavor, 3 Oz, Pack of 24\": \"Instant ramen noodles with creamy ch...\n",
      "Error parsing candidate_perception (custom_id: 417172): \n",
      "    \"Swerve Sweetener, Confectioners, 12 oz\": \"Perfect addition to low-carb diet\",\n",
      "    \"Raw Brazil ...\n",
      "Error parsing user_history_perception (custom_id: 419616): \n",
      "    \"Betty Crocker Suddenly Pasta Salad, Classic Pasta Salad, 15.5 oz\": \"Instant pasta salad mix th...\n",
      "    Extracted 591 entries\n",
      "    Failed: 1 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part1_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 11418): \n",
      "    \"Folgers 100% Colombian Medium Roast Coffee, 22.6 Ounces (Pack of 6)\": \"Coffee may not align wi...\n",
      "    Extracted 799 entries\n",
      "    Failed: 1 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part2_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 46527): \n",
      "    \"Fresh Roasted Coffee, Sumatra Mandheling, 2 lb (32 oz), Medium Roast, Kosher, Whole Bean\": \"Ri...\n",
      "Error parsing candidate_temp_perception (custom_id: 53174): \n",
      "    \"Lavazza Crema E Gusto Whole Bean Coffee 1 kg Bag, Authentic Italian, Blended and roasted in It...\n",
      "Error parsing candidate_temp_perception (custom_id: 63340): \n",
      "    \"Quaker Chewy Granola Bars, Oatmeal Raisin, 58 Count\": \"Granola bars made with oatmeal and rais...\n",
      "    Extracted 799 entries\n",
      "    Failed: 1 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part3_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 71497): \n",
      "    \"Fresh Roasted Coffee, Sumatra Mandheling, 2 lb (32 oz), Medium Roast, Kosher, Whole Bean\": \"Wh...\n",
      "Error parsing candidate_temp_perception (custom_id: 81790): \n",
      "    \"Healthworks Cacao Powder (32 Ounces / 2 Pounds)\": \"Organic cacao powder that is sugar-free, ke...\n",
      "Error parsing candidate_temp_perception (custom_id: 83619): \n",
      "    \"Jordan's Sugar-Free Flavored Skinny Syrup, Large 25.4-oz. Bottle (Lemon Elderflower) with Zero...\n",
      "Error parsing user_history_perception (custom_id: 88162): \n",
      "    \"Cheribundi ORIGINAL Tart Cherry Juice - Pro Athlete Workout Recovery - Fight Inflammation and ...\n",
      "Error parsing candidate_temp_perception (custom_id: 89408): \n",
      "    \"Harney & Sons Flavored Black Tea, Paris\": \"Black tea blended with flavors of vanilla and caram...\n",
      "Error parsing candidate_temp_perception (custom_id: 93916): \n",
      "    \"ChocZero's Strawberry Sugar-Free Syrup\": \"Low carb strawberry syrup with no preservatives or s...\n",
      "    Extracted 800 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part4_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 106734): \n",
      "    \"Tassimo King of Joe Dark Roast Bold Roast Coffee T-Discs for Tassimo Single Cup Home Brewing S...\n",
      "Error parsing candidate_perception (custom_id: 107101): \n",
      "    \"Carnation Breakfast Essentials Powder Drink Mix, Classic French Vanilla, 10 Count Box of Packe...\n",
      "Error parsing candidate_perception (custom_id: 107614): \n",
      "    \"Victor Allen's Coffee Caramel Macchiato, Medium Roast, 80 Count, Single Serve Coffee Pods for ...\n",
      "Error parsing candidate_temp_perception (custom_id: 108513): \n",
      "    \"Stella Blue Fresh Ground Coffee - Big Cat Blend - 100% Arabica MEDIUM Roast - Ethically & Sust...\n",
      "Error parsing candidate_temp_perception (custom_id: 111951): \n",
      "    \"Victor Allen's Coffee Caramel Macchiato, Medium Roast, 80 Count, Single Serve Coffee Pods for ...\n",
      "Error parsing candidate_temp_perception (custom_id: 112216): \n",
      "    \"Amazon Brand - Solimo Medium Roast Coffee Pods, Donut Style, Compatible with Keurig 2.0 K-Cup ...\n",
      "Error parsing user_history_perception (custom_id: 113001): \n",
      "    \"365 Everyday Value, Saltine Crackers, 16 Ounce\": \"Classic crispy crackers, low in calories and...\n",
      "Error parsing candidate_perception (custom_id: 117074): \n",
      "    \"Don Pablo Gourmet Coffee - Signature Blend - Medium Dark Roast - Whole Bean Coffee - 100% Arab...\n",
      "Error parsing user_history_perception (custom_id: 129752): \n",
      "    \"Variety Pack of Coffee, Tea, Hot Chocolate and Cappuccino, Sampler of Single Serve Coffee, Tea...\n",
      "    Extracted 797 entries\n",
      "    Failed: 3 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part5_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 140327): \n",
      "    \"Droste Cocoa Powder Dutch Style Cocoa for Baking Desserts and More, 8.8 Ounce (Pack of 3)\": \"R...\n",
      "Error parsing candidate_temp_perception (custom_id: 141944): \n",
      "    \"Slim Jim Original 'N Cheese, Original Flavor, 0.9 oz 10 ct\": \"Beef jerky stick with cheese, pr...\n",
      "Error parsing candidate_temp_perception (custom_id: 144728): \n",
      "    \"Fresh Roasted Coffee, Sumatra Mandheling, 2 lb (32 oz), Medium Roast, Kosher, Whole Bean\": \"Wh...\n",
      "Error parsing candidate_temp_perception (custom_id: 151903): \n",
      "    \"50 Nespresso OriginalLine Capsules variety pack: Intense Family - ''NOT compatible with Vertuo...\n",
      "Error parsing user_history_perception (custom_id: 154697): \n",
      "    \"Walkers Shortbread Highland Oat Crackers, 10.6-Ounce Boxes (Count of 4)\": \"Traditional Scottis...\n",
      "Error parsing candidate_temp_perception (custom_id: 157577): \n",
      "    \"HighKey Low Carb Keto Cereal\": \"Chocolate cereal with zero sugar and gluten-free, ideal for ke...\n",
      "Error parsing candidate_temp_perception (custom_id: 162782): \n",
      "    \"Death Wish Coffee Whole Bean Dark Roast - Extra Kick of Caffeine - USA Organic Coffee Beans Bu...\n",
      "Error parsing candidate_perception (custom_id: 171786): \n",
      "    \"HighKey Sugar Free Chocolate Candies - Keto Snack Dark Chocolate Almond Caramel Nut Clusters G...\n",
      "    Extracted 799 entries\n",
      "    Failed: 1 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part6_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 179094): \n",
      "    \"Great Lakes Wellness Culinary Beef Gelatin Powder - Unflavored - Grass-Fed, Kosher, KETO, Pale...\n",
      "Error parsing candidate_temp_perception (custom_id: 184053): \n",
      "    \"HighKey Low Carb Keto Cereal\": \"Protein-rich, zero-sugar chocolate cereal, gluten-free, suitab...\n",
      "Error parsing candidate_temp_perception (custom_id: 185401): \n",
      "    \"Door County Coffee - Breakfast Blend Decaf, Ground Coffee - Medium Roast, 10 oz Bag\": \"Decaf m...\n",
      "Error parsing candidate_perception (custom_id: 200448): \n",
      "    \"Organic Granular Stevia Sweetener Blend, All-Purpose Sugar Substitute, Keto, 12 oz (340 g), Py...\n",
      "Error parsing candidate_temp_perception (custom_id: 201844): \n",
      "    \"Terrasoul Superfoods Organic Medjool Dates, 4 Lbs - Soft Chewy Texture | Sweet Caramel Flavor ...\n",
      "Error parsing candidate_perception (custom_id: 207541): \n",
      "    \"Black Rifle Coffee Rounds (Just Black (Medium Roast), 32 Count)\": \"May not align with dark roa...\n",
      "Error parsing candidate_temp_perception (custom_id: 209546): \n",
      "    \"Kinder Bueno Milk Chocolate and Hazelnut Cream, 2 Individually Wrapped Chocolate Bars Per Pack...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part7_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 218528): \n",
      "    \"Amazon Brand - Solimo Medium Roast Coffee Pods\": \"Convenient coffee option in large quantity\",...\n",
      "Error parsing candidate_perception (custom_id: 227189): \n",
      "    \"Nielsen-Massey Pure Almond Extract, with Gift Box, 18 ounces\": \"Enhances baking with natural f...\n",
      "Error parsing candidate_perception (custom_id: 230210): \n",
      "    \"True Lime Black Cherry Limeade, 10 Count, Pack of 2\": \"Refreshing and sugar-free hydration opt...\n",
      "Error parsing candidate_perception (custom_id: 234554): \n",
      "    \"Subtle Earth Organic Coffee - Medium-Dark Roast - Whole Bean Coffee - 100% Arabica Beans - Low...\n",
      "Error parsing candidate_perception (custom_id: 242289): \n",
      "    \"Slim Jim Original 'N Cheese, Original Flavor, 0.9 oz 10 ct\": \"Processed snack that may not fit...\n",
      "Error parsing candidate_perception (custom_id: 243369): \n",
      "    \"Carbquik Biscuit & Baking Mix\": \"Perfect for low-sugar meal options\",\n",
      "    \"True Lime Black Che...\n",
      "Error parsing candidate_perception (custom_id: 245671): \n",
      "    \"SweetLeaf Sweet Drops Stevia Clear Liquid Stevia Sweetener\": \"Focus on sweetening rather than ...\n",
      "    Extracted 793 entries\n",
      "    Failed: 7 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part8_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 256551): \n",
      "    \"Hint Water Peach, Pure Water Infused with Peach, Zero Sugar, Zero Calories, Zero Sweeteners, Z...\n",
      "Error parsing candidate_temp_perception (custom_id: 262614): \n",
      "    \"Lakanto Golden Monk Fruit Sweetener with Erythritol\": \"Zero-calorie, keto-friendly sugar subst...\n",
      "Error parsing candidate_temp_perception (custom_id: 266182): \n",
      "    \"Walker's Shortbread Gluten Free Variety Pack, 2 of Each: Shortbread Rounds, Chocolate Chip, Gi...\n",
      "Error parsing candidate_temp_perception (custom_id: 272192): \n",
      "    \"Fresh Roasted Coffee, Sumatra Mandheling, 2 lb (32 oz), Medium Roast, Kosher, Whole Bean\": \"Me...\n",
      "Error parsing candidate_temp_perception (custom_id: 277642): \n",
      "    \"Maruchan Instant Lunch Lime Chicken Flavor, 2.25 Oz, Pack of 12\": \"Instant ramen cups flavored...\n",
      "Error parsing candidate_temp_perception (custom_id: 278195): \n",
      "    \"Sincerely Nuts Sunflower Seeds Roasted and Salted, Hulled | No Shell, Gluten-Free Snack, Vegan...\n",
      "Error parsing candidate_temp_perception (custom_id: 284930): \n",
      "    \"Blue Diamond Almonds Whole Natural Raw Snack Nuts, 40 Oz Resealable Bag\": \"Raw almonds, natura...\n",
      "    Extracted 800 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_valid_part9_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 291852): \n",
      "    \"DEATH WISH COFFEE Espresso Roast Single Serve Coffee Pods - Extra Kick of Caffeine - Fair Trad...\n",
      "Error parsing candidate_temp_perception (custom_id: 300193): \n",
      "    \"Lakanto Golden Monk Fruit Sweetener with Erythritol\": \"A zero-calorie sugar substitute combini...\n",
      "Error parsing candidate_perception (custom_id: 312633): \n",
      "    \"True Lime Black Cherry Limeade, 10 Count, Pack of 2\": \"Complementary flavorful beverage\",\n",
      "    ...\n",
      "Error parsing candidate_perception (custom_id: 314268): \n",
      "    \"Katz Gluten Free Marble Loaf | Dairy Free, Nut Free, Soy Free, Gluten Free | Kosher (6 Packs o...\n",
      "Error parsing candidate_temp_perception (custom_id: 316402): \n",
      "    \"Lavazza Crema E Gusto Whole Bean Coffee\": \"Authentic Italian coffee, full-bodied and creamy da...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "\n",
      "  Total extracted for valid: 9373 users\n",
      "\n",
      "Processing test phase...\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part10_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 415310): \n",
      "    \"Kellogg's Pop-Tarts Frosted Brown Sugar Cinnamon - Toaster Pastries Breakfast for Kids, Value ...\n",
      "Error parsing candidate_temp_perception (custom_id: 417221): \n",
      "    \"Yogi Tea Herbal Stress Relief, Honey Lavender\": \"Herbal tea designed for stress relief with ho...\n",
      "Error parsing candidate_temp_perception (custom_id: 419430): \n",
      "    \"Goldfish Cheddar Crackers, Snack Crackers, 30 oz carton, 2 CT box\": \"Cheddar-flavored snack cr...\n",
      "    Extracted 461 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part2_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 52670): \n",
      "    \"Lakanto Golden Monk Fruit Sweetener with Erythritol - Raw Cane Sugar Substitute, Zero Calorie,...\n",
      "Error parsing user_history_perception (custom_id: 59238): \n",
      "    \"Amazon Brand - Happy Belly Organic Virgin Coconut Oil, Unrefined, Non-GMO, 15 Fl Oz\": \"Unrefin...\n",
      "Error parsing candidate_perception (custom_id: 70230): \n",
      "    \"Bigelow Tea Darjeeling Black Tea, Caffeinated, 20 Count\": \"Quality Darjeeling tea matches user...\n",
      "Error parsing candidate_temp_perception (custom_id: 83258): \n",
      "    \"Newman's Own Organics Special Blend Decaf, Single-Serve Keurig K-Cup Pods, Medium Roast Coffee...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part3_result.jsonl...\n",
      "Error parsing user_history_perception (custom_id: 89144): \n",
      "    \"Organic Prairie Pasture Raised 85% Lean Organic Ground Beef, 1 lb\": \"Lean organic ground beef ...\n",
      "Error parsing candidate_temp_perception (custom_id: 91815): \n",
      "    \"Stash Tea Chamomile Nights Herbal Tea, Box of 100 Tea Bags (Packaging May Vary)\": \"Herbal tea ...\n",
      "Error parsing candidate_temp_perception (custom_id: 92346): \n",
      "    \"The Switch Sparkling Juice, Lemon Lime, 8-Ounce Cans (Pack of 24)\": \"Sparkling juice drink wit...\n",
      "Error parsing candidate_temp_perception (custom_id: 102349): \n",
      "    \"The Spice Lab Himalayan Salt - Coarse 2.2 Lb / 1 Kilo - Pink Himalayan Salt is Nutrient and Mi...\n",
      "Error parsing candidate_temp_perception (custom_id: 105997): \n",
      "    \"Jayone Seaweed, Roasted and Lightly Salted, 0.17 Ounce (Pack of 24)\": \"Roasted seaweed snacks ...\n",
      "Error parsing candidate_temp_perception (custom_id: 109717): \n",
      "    \"Slim Jim Original 'N Cheese, Original Flavor, 0.9 oz 10 ct\": \"Beef snack sticks with a cheesy ...\n",
      "Error parsing candidate_temp_perception (custom_id: 126436): \n",
      "    \"Zevia Zero Calorie Soda, Lemon Lime Twist, 12 Ounce Sleek Can\": \"Zero-calorie soda with a lemo...\n",
      "Error parsing candidate_temp_perception (custom_id: 127082): \n",
      "    \"San Francisco Bay Compostable Coffee Pods - Fog Chaser (12 Ct) K Cup Compatible including Keur...\n",
      "Error parsing candidate_temp_perception (custom_id: 128768): \n",
      "    \"Cheerios Blueberry Heart Healthy Cereal, Gluten Free Cereal With Whole Grain Oats, 14.2 OZ Lar...\n",
      "    Extracted 800 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part4_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 134223): \n",
      "    \"The Spice Lab Himalayan Salt - Coarse 2.2 Lb / 1 Kilo\": \"Nutrient-rich pink Himalayan salt, na...\n",
      "Error parsing candidate_temp_perception (custom_id: 135897): \n",
      "    \"Amazon Brand - Solimo Medium Roast Coffee Pods, Donut Style, Compatible with Keurig 2.0 K-Cup ...\n",
      "Error parsing user_history_perception (custom_id: 139565): \n",
      "    \"Utz Pork Rinds, Original Flavor\": \"Keto-friendly snack made from fried pork skin, with zero ca...\n",
      "Error parsing candidate_temp_perception (custom_id: 143728): \n",
      "    \"Lakanto Golden Monk Fruit Sweetener with Erythritol - Raw Cane Sugar Substitute, Zero Calorie,...\n",
      "Error parsing candidate_temp_perception (custom_id: 153264): \n",
      "    \"True Lime Black Cherry Limeade, 10 Count, Pack of 2\": \"Sugar-free limeade drink mixes with bla...\n",
      "    Extracted 800 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part5_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 172695): \n",
      "    \"FGO Organic Rosehips Tea, Eco-Conscious Tea Bags, 20 Count (Pack of 1)\": \"Organic rosehip tea ...\n",
      "Error parsing candidate_perception (custom_id: 180543): \n",
      "    \"Nature Nate's 100% Pure Organic, Raw & Unfiltered. Squeeze Bottle; Allnatural Sweetener, USDA ...\n",
      "Error parsing candidate_perception (custom_id: 200718): \n",
      "    \"Death Wish Coffee Blue and Buried, Fair Trade, Ground Blueberry Coffee, 12 oz\": \"Unique flavor...\n",
      "Error parsing candidate_temp_perception (custom_id: 201805): \n",
      "    \"Celestial Seasonings Herbal Tea, Honey Vanilla Chamomile, Caffeine Free, 20 Tea Bags (Pack of ...\n",
      "Error parsing candidate_temp_perception (custom_id: 202469): \n",
      "    \"Premier Protein Shake, Cookies & Cream, 30g Protein, 1g Sugar, 24 Vitamins & Minerals, Nutrien...\n",
      "Error parsing candidate_perception (custom_id: 207025): \n",
      "    \"OREO Original, OREO Golden, CHIPS AHOY! & Nutter Butter Cookie Snacks Variety Pack, School Lun...\n",
      "    Extracted 797 entries\n",
      "    Failed: 3 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part6_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 222674): \n",
      "    \"Livlo Keto Bread Mix\": \"Convenient for low-carb baking\",\n",
      "    \"Lakanto Sugar Free Chocolate Chi...\n",
      "Error parsing candidate_temp_perception (custom_id: 230274): \n",
      "    \"Quaker Protein Instant Oatmeal, Banana Nut, 10g Protein, Individual Packets, 36 Count\": \"Insta...\n",
      "Error parsing candidate_temp_perception (custom_id: 231845): \n",
      "    \"Crystal+Light+On+The+Go+Raspberry+Lemonade+Drink+Mix, 10-Packet Box (Pack of 9)\": \"Sugar-free ...\n",
      "Error parsing candidate_perception (custom_id: 234539): \n",
      "    \"Mission Meats Sugar Free Grass Fed Beef Sticks Gluten Free Paleo Healthy School Snacks for Kid...\n",
      "Error parsing candidate_temp_perception (custom_id: 252533): \n",
      "    \"Fresh Roasted Coffee, Sumatra Mandheling, 2 lb (32 oz), Medium Roast, Kosher, Whole Bean\": \"Me...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part7_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 268194): \n",
      "    \"Grove Square Cappuccino Cups, French Vanilla, Single Serve Cup for Keurig K-Cup Brewers, 24 Co...\n",
      "Error parsing candidate_temp_perception (custom_id: 269519): \n",
      "    \"Subtle Earth Organic Coffee - Medium-Dark Roast - Whole Bean Coffee - 100% Arabica Beans - Low...\n",
      "Error parsing candidate_perception (custom_id: 270924): \n",
      "    \"San Francisco Bay Compostable Coffee Pods - Fog Chaser (12 Ct)\": \"Good dark roast with eco-fri...\n",
      "Error parsing candidate_temp_perception (custom_id: 271586): \n",
      "    \"Amazon Brand - Happy Belly Fruit & Grain Cereal Bars, Apple Cinnamon\": \"Cereal bars made with ...\n",
      "Error parsing candidate_perception (custom_id: 275535): \n",
      "    \"Snack Pack Chocolate and Vanilla Pudding Cups Family Pack, 12 Count (Pack of 1)\": \"Convenient ...\n",
      "Error parsing candidate_temp_perception (custom_id: 287075): \n",
      "    \"Green Mountain Coffee Roasters Sumatra Reserve Keurig Single-Serve K-Cup Pods, Dark Roast Coff...\n",
      "Error parsing candidate_temp_perception (custom_id: 292997): \n",
      "    \"Nestle Coffee mate Coffee Creamer, Peppermint Mocha, Liquid Creamer Singles, Non Dairy, No Ref...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part8_result.jsonl...\n",
      "Error parsing candidate_perception (custom_id: 307892): \n",
      "    \"True Lime Black Cherry Limeade\": \"Not ideal as a replacement for gourmet treats.\",\n",
      "    \"Royal ...\n",
      "Error parsing candidate_temp_perception (custom_id: 316043): \n",
      "    \"SNAPPY Grape Sno Cone Syrup, 1 Gallon, 11 Pound\": \"Grape-flavored syrup for snow cones, provid...\n",
      "Error parsing candidate_perception (custom_id: 346570): \n",
      "    \"Stash Tea Chamomile Nights Herbal Tea, Box of 100 Tea Bags (Packaging May Vary)\": \"Could provi...\n",
      "    Extracted 798 entries\n",
      "    Failed: 2 entries\n",
      "  Processing Grocery_and_Gourmet_Food_random_test_part9_result.jsonl...\n",
      "Error parsing candidate_temp_perception (custom_id: 355289): \n",
      "    \"Feel Good Foods Potstickers Vegetable Box, 10 Oz\": \"Vegetable potstickers filled with a mix of...\n",
      "Error parsing candidate_temp_perception (custom_id: 367992): \n",
      "    \"Trident Lime Passion Fruit Twist Sugar Free Gum, 12 Packs of 14 Pieces (168 Total Pieces)\": \"S...\n",
      "Error parsing candidate_temp_perception (custom_id: 374997): \n",
      "    \"14oz Arrow Root Starch Bot San Day by Fortuna (Pack of 1)\": \"Gluten-free arrowroot starch suit...\n",
      "Error parsing candidate_temp_perception (custom_id: 384043): \n",
      "    \"Jordan's Skinny Syrups Butter Toffee, Sugar Free Coffee Flavoring Syrup, 25.4 Ounce Bottle (Pa...\n",
      "Error parsing candidate_temp_perception (custom_id: 390113): \n",
      "    \"Crystal+Light+On+The+Go+Raspberry+Lemonade+Drink+Mix%2c+10-Packet+Box+(Pack+of+9)\": \"Portable ...\n",
      "    Extracted 799 entries\n",
      "    Failed: 1 entries\n",
      "\n",
      "  Total extracted for test: 6849 users\n",
      "\n",
      "‚úÖ Step 1.8 Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Step 1.8: Parsing GPT Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = {'valid': {}, 'test': {}}\n",
    "\n",
    "for phase in ['valid', 'test']:\n",
    "    print(f\"\\nProcessing {phase} phase...\")\n",
    "    phase_results = {}\n",
    "\n",
    "    # Process all result files for this phase\n",
    "    result_files = sorted(glob.glob(f\"{DATASET_NAME}_{MODE}_{phase}_part*_result.jsonl\"))\n",
    "\n",
    "    for result_file in result_files:\n",
    "        print(f\"  Processing {result_file}...\")\n",
    "        result, failed_ids = process_jsonl_file(result_file)\n",
    "\n",
    "        # Merge results\n",
    "        for user_id, content in result.items():\n",
    "            phase_results[user_id] = content\n",
    "\n",
    "        print(f\"    Extracted {len(result)} entries\")\n",
    "        if failed_ids:\n",
    "            print(f\"    Failed: {len(failed_ids)} entries\")\n",
    "\n",
    "    all_results[phase] = phase_results\n",
    "    print(f\"\\n  Total extracted for {phase}: {len(phase_results)} users\")\n",
    "\n",
    "print(\"\\n‚úÖ Step 1.8 Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl13hrQmJi9I"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1763800008033,
     "user": {
      "displayName": "Tom Twan",
      "userId": "01823172147373690392"
     },
     "user_tz": 300
    },
    "id": "hK0yv_8SJi9I",
    "outputId": "3678269b-b955-4040-f64d-b57c37ec56c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1.9: Saving Final Results\n",
      "============================================================\n",
      "\n",
      "‚úÖ Saved validation results: Grocery_and_Gourmet_Food_valid.pkl\n",
      "   Users: 9373\n",
      "\n",
      "‚úÖ Saved test results: Grocery_and_Gourmet_Food_test.pkl\n",
      "   Users: 6849\n",
      "\n",
      "üìã Sample result (user 321648):\n",
      "   Preferences: The user enjoys sweet beverages and flavors, particularly hot cocoa and flavored drink mixes, with a...\n",
      "   Perceptions: 10 items\n",
      "   Example: Crush, Grape ‚Äì Powder Drink Mix - (12 boxes, 72 sticks) ‚Äì Sugar Free & Delicious, Makes 72 flavored water beverages -> Appealing sugar-free grape flavor.\n",
      "\n",
      "============================================================\n",
      "üéâ Stage 1 Complete!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "1. Use the pickle files in Stage 2 (0_Grocery_and_Gourmet_Food_sft1.py)\n",
      "2. Train LLM model with personalized information\n",
      "3. Run inference (2_inference.py)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Step 1.9: Saving Final Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save validation results\n",
    "valid_output_file = f'{DATASET_NAME}_valid.pkl'\n",
    "with open(valid_output_file, 'wb') as file:\n",
    "    pickle.dump(all_results['valid'], file)\n",
    "print(f\"\\n‚úÖ Saved validation results: {valid_output_file}\")\n",
    "print(f\"   Users: {len(all_results['valid'])}\")\n",
    "\n",
    "# Save test results\n",
    "test_output_file = f'{DATASET_NAME}_test.pkl'\n",
    "with open(test_output_file, 'wb') as file:\n",
    "    pickle.dump(all_results['test'], file)\n",
    "print(f\"\\n‚úÖ Saved test results: {test_output_file}\")\n",
    "print(f\"   Users: {len(all_results['test'])}\")\n",
    "\n",
    "# Display sample result\n",
    "if all_results['valid']:\n",
    "    sample_user = list(all_results['valid'].keys())[0]\n",
    "    print(f\"\\nüìã Sample result (user {sample_user}):\")\n",
    "    sample = all_results['valid'][sample_user]\n",
    "    print(f\"   Preferences: {sample['user_preferences'][:100]}...\")\n",
    "    print(f\"   Perceptions: {len(sample['candidate_perception'])} items\")\n",
    "    if sample['candidate_perception']:\n",
    "        first_item = list(sample['candidate_perception'].keys())[0]\n",
    "        print(f\"   Example: {first_item} -> {sample['candidate_perception'][first_item]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Stage 1 Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Use the pickle files in Stage 2 (0_Grocery_and_Gourmet_Food_sft1.py)\")\n",
    "print(\"2. Train LLM model with personalized information\")\n",
    "print(\"3. Run inference (2_inference.py)\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
